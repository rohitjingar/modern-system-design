# 45. Metrics (Prometheus, Grafana)

You need to know what's happening in your system, so you collect metrics. You collect so many metrics that you run out of storage. So you delete old metrics. Then the one time you need historical data? Gone. You invent compression schemes. Still not enough. You build sophisticated sampling. Now you have no data when things go wrong. Metrics: helping you understand nothing in excruciating detail! ğŸ“ŠğŸ˜¤

[â† Back to Main](../README.md) | [Previous: Logging, Monitoring & Observability](44-logging-monitoring-alerting.md) | [Next: Tracing (Jaeger, OpenTelemetry)](46-tracing-jaeger.md)

---

## ğŸ¯ Quick Summary

**Metrics** are quantitative measurements (CPU, memory, latency, errors). **Prometheus** scrapes time-series data every 15 seconds. **Grafana** visualizes metrics in dashboards. Netflix generates billions of metrics daily. Google uses similar systems internally. Metrics enable: alerting (CPU > 80%), trending (traffic growing), debugging (what changed?). Trade-off: storage (massive), cardinality explosion (too many labels), staleness (15s delay). Essential for production visibility.

Think of it as: **Metrics = System Heartbeat**

---

## ğŸŒŸ Beginner Explanation

### Types of Metrics

```
COUNTER (Always increasing):

Request counter:
â”œâ”€ T=0: requests_total = 1000
â”œâ”€ T=1: requests_total = 1001
â”œâ”€ T=2: requests_total = 1005
â”œâ”€ T=3: requests_total = 1010
â””â”€ Only goes up (or resets on restart)

Uses:
â”œâ”€ Total requests
â”œâ”€ Total errors
â”œâ”€ Total bytes sent
â””â”€ Can only increase

Useful for:
â”œâ”€ Rate calculation (requests/sec = delta/time)
â”œâ”€ Error counting
â”œâ”€ Tracking work done


GAUGE (Can go up or down):

Memory usage:
â”œâ”€ T=0: memory_bytes = 1,000,000,000
â”œâ”€ T=1: memory_bytes = 1,100,000,000 (â†‘ increased)
â”œâ”€ T=2: memory_bytes = 900,000,000 (â†“ decreased)
â”œâ”€ T=3: memory_bytes = 950,000,000 (â†‘ increased again)
â””â”€ Goes up and down freely

Uses:
â”œâ”€ Current memory
â”œâ”€ Current connections
â”œâ”€ Current queue length
â””â”€ Can be any value

Useful for:
â”œâ”€ Current state
â”œâ”€ Capacity tracking
â”œâ”€ Resource utilization


HISTOGRAM (Distribution of values):

Request latency:
â”œâ”€ Bucket < 10ms: 500 requests
â”œâ”€ Bucket < 50ms: 4,500 requests
â”œâ”€ Bucket < 100ms: 4,800 requests
â”œâ”€ Bucket < 500ms: 4,950 requests
â”œâ”€ Bucket < 1000ms: 4,999 requests
â””â”€ Bucket < inf: 5000 requests

Useful for:
â”œâ”€ Percentiles (p50, p99, p999)
â”œâ”€ Understanding distribution
â”œâ”€ Alerting on slowness


SUMMARY (Histogram alternative):

Request latency (quantiles):
â”œâ”€ p50 (median): 45ms
â”œâ”€ p90: 120ms
â”œâ”€ p99: 450ms
â”œâ”€ p99.9: 850ms
â”œâ”€ Total count: 5000
â””â”€ Total sum: 225,000ms

Difference from histogram:
â”œâ”€ Histogram: Calculated by client
â”œâ”€ Summary: Calculated by server
â””â”€ Both allow percentile calculation
```

### Prometheus Architecture

```
SCRAPING (Pull model):

Prometheus server:
â”œâ”€ Every 15 seconds (configurable)
â”œâ”€ Scrapes each target
â”œâ”€ GET http://target:9090/metrics
â”œâ”€ Receives metrics text format
â”œâ”€ Stores in time-series database
â””â”€ Repeat forever

Target (application):
â”œâ”€ Exports metrics endpoint
â”œâ”€ GET /metrics returns:
â”‚  â”œâ”€ requests_total{path="/api"} 1000
â”‚  â”œâ”€ request_duration_seconds 0.045
â”‚  â”œâ”€ memory_bytes 1000000
â”‚  â””â”€ ... more metrics
â””â”€ Prometheus scrapes it

Storage:
â”œâ”€ Time-series database (on disk)
â”œâ”€ Fast query for ranges
â”œâ”€ Stores: (metric, labels, timestamp, value)
â””â”€ Default: 15 days retention

Query:
â”œâ”€ PromQL (Prometheus Query Language)
â”œâ”€ SELECT requests_total WHERE path="/api"
â”œâ”€ Returns: Time series of values
â””â”€ Grafana visualizes


PUSH MODEL (Alternative):

Some systems push metrics (instead of pull):
â”œâ”€ Application sends data
â”œâ”€ To: Metrics aggregator
â”œâ”€ Every: 1 minute (or batched)

Push example:
â”œâ”€ Datadog
â”œâ”€ CloudWatch
â”œâ”€ InfluxDB
â””â”€ (Pull is more common)

Prometheus uses PULL (not push)
```

### PromQL (Query Language)

```
BASIC QUERIES:

Get all CPU usage:
â”œâ”€ cpu_usage_percent
â””â”€ Returns: All CPU metrics

Filter by label:
â”œâ”€ cpu_usage_percent{host="server1"}
â””â”€ Returns: CPU only for server1

Multiple labels:
â”œâ”€ requests_total{path="/api", method="GET"}
â””â”€ Returns: GET requests to /api


AGGREGATION:

Sum across instances:
â”œâ”€ sum(requests_total)
â””â”€ Returns: Total requests across all servers

Average:
â”œâ”€ avg(request_duration_seconds)
â””â”€ Returns: Average latency

Percentile:
â”œâ”€ histogram_quantile(0.99, request_duration_seconds_bucket)
â””â”€ Returns: P99 latency


TIME RANGE:

Last 5 minutes:
â”œâ”€ requests_total[5m]
â””â”€ Returns: Time series for last 5 minutes

Rate calculation:
â”œâ”€ rate(requests_total[5m])
â””â”€ Returns: Requests per second

Increase over time:
â”œâ”€ increase(requests_total[1h])
â””â”€ Returns: How many requests in last hour


ALERTING QUERIES:

Alert if CPU > 80%:
â”œâ”€ cpu_usage_percent > 80
â””â”€ Triggers: Alert when true

Alert if error rate > 1%:
â”œâ”€ (rate(errors_total[5m]) / rate(requests_total[5m])) > 0.01
â””â”€ Triggers: If error rate exceeds 1%
```

---

## ğŸ”¬ Advanced Explanation

### Cardinality Explosion

```
WHAT IS CARDINALITY?

Each unique combination of label values = 1 metric

Example:
â”œâ”€ Metric: request_duration
â”œâ”€ Labels: path, method, status, host

Values:
â”œâ”€ path: 100 endpoints
â”œâ”€ method: 5 values (GET, POST, PUT, DELETE, PATCH)
â”œâ”€ status: 20 values (200, 201, 400, 401, 403, 404, 500, etc)
â”œâ”€ host: 50 servers

Total cardinality:
â”œâ”€ 100 Ã— 5 Ã— 20 Ã— 50 = 500,000 metrics!
â””â”€ For ONE metric type!

Problem:
â”œâ”€ Storage explodes
â”œâ”€ Query performance degrades
â”œâ”€ RAM usage increases
â””â”€ Prometheus slows down


PREVENTION:

1. Limit labels:
   â”œâ”€ Don't label everything
   â”œâ”€ Only label what you need
   â””â”€ Avoid customer_id as label (infinite values!)

2. Use static labels:
   â”œâ”€ Put const values elsewhere
   â”œâ”€ Or aggregate server-side
   â””â”€ Don't expose as labels

3. Monitor cardinality:
   â”œâ”€ Track number of metrics
   â”œâ”€ Alert if growing too fast
   â””â”€ Investigate new labels
```

### Storage & Retention

```
STORAGE CALCULATION:

Disk space per metric:
â”œâ”€ Timestamp: 8 bytes
â”œâ”€ Value: 8 bytes
â”œâ”€ Total: ~16 bytes per data point

Scrape interval: 15 seconds
Data points per metric per day:
â”œâ”€ 24 hours Ã— 60 min Ã— 60 sec / 15 sec = 5,760 data points
â”œâ”€ Per day per metric

If you have 10,000 metrics:
â”œâ”€ 10,000 metrics Ã— 5,760 points = 57.6M points/day
â”œâ”€ 57.6M Ã— 16 bytes = 921 MB/day
â”œâ”€ 921 MB Ã— 365 days = 336 GB/year!

With 1TB storage:
â”œâ”€ 1000 GB / 336 GB per year = ~3 years

RETENTION STRATEGIES:

Default (15 days):
â”œâ”€ Store: 15 days of high-resolution
â”œâ”€ Delete: Older data

Tiered storage:
â”œâ”€ Hot: 15 days (15 second resolution)
â”œâ”€ Warm: 90 days (1 minute resolution)
â”œâ”€ Cold: Archive (downsampled)

Downsampling:
â”œâ”€ After 7 days: Reduce resolution
â”œâ”€ Keep: 1 point per minute (was 4/min)
â”œâ”€ 75% storage savings!
â””â”€ Good for: Trending, still lose detail
```

### Grafana Dashboards

```
DASHBOARD TYPES:

Real-time (Live):
â”œâ”€ Update: Every refresh (1-5 seconds)
â”œâ”€ Retention: Current state
â”œâ”€ Use: Current issues, active debugging
â””â”€ Example: CPU, memory NOW

Time-series (Historical):
â”œâ”€ Update: As data comes in
â”œâ”€ Retention: Full history
â”œâ”€ Use: Trending, capacity planning
â””â”€ Example: CPU over last week

Heatmap:
â”œâ”€ Shows: Distribution over time
â”œâ”€ X-axis: Time
â”œâ”€ Y-axis: Value range
â”œâ”€ Color: Frequency
â””â”€ Use: Latency distribution

Table:
â”œâ”€ Shows: Raw data
â”œâ”€ Sortable: By any column
â”œâ”€ Use: Detailed investigation
â””â”€ Example: Top N queries
```

---

## ğŸ Python Code Example

### âŒ Without Metrics (No Visibility)

```python
# ===== NO METRICS =====

from flask import Flask

app = Flask(__name__)

@app.route('/api/orders', methods=['POST'])
def create_order():
    """Create order - no metrics"""
    
    try:
        order = process_order(request.json)
        return {'order_id': order.id}
    except Exception as e:
        print(f"Error: {e}")  # Logging only!
        return {'error': 'Failed'}, 500

# Problems:
# âŒ No metrics
# âŒ No visibility into performance
# âŒ Can't see traffic patterns
# âŒ Can't alert on issues
# âŒ Debugging: Logs only (slow)
```

### âœ… With Prometheus Metrics

```python
# ===== WITH PROMETHEUS METRICS =====

from flask import Flask
from prometheus_client import Counter, Histogram, Gauge, generate_latest

app = Flask(__name__)

# Define metrics
requests_total = Counter(
    'requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

request_duration_seconds = Histogram(
    'request_duration_seconds',
    'HTTP request duration',
    ['endpoint'],
    buckets=(0.01, 0.05, 0.1, 0.5, 1.0, 5.0)
)

orders_processing = Gauge(
    'orders_processing',
    'Orders currently being processed'
)

@app.route('/api/orders', methods=['POST'])
def create_order():
    """Create order with metrics"""
    
    orders_processing.inc()  # Increment gauge
    
    start_time = time.time()
    
    try:
        order = process_order(request.json)
        
        # Record success
        duration = time.time() - start_time
        request_duration_seconds.labels(endpoint='/api/orders').observe(duration)
        requests_total.labels(
            method='POST',
            endpoint='/api/orders',
            status='201'
        ).inc()
        
        return {'order_id': order.id}, 201
    
    except Exception as e:
        # Record error
        duration = time.time() - start_time
        request_duration_seconds.labels(endpoint='/api/orders').observe(duration)
        requests_total.labels(
            method='POST',
            endpoint='/api/orders',
            status='500'
        ).inc()
        
        return {'error': str(e)}, 500
    
    finally:
        orders_processing.dec()  # Decrement gauge

@app.route('/metrics', methods=['GET'])
def metrics():
    """Prometheus scrapes this endpoint"""
    
    return generate_latest()

# Benefits:
# âœ… Visibility into traffic
# âœ… Performance metrics
# âœ… Error tracking
# âœ… Prometheus compatible
```

### âœ… Production Metrics (Advanced)

```python
# ===== PRODUCTION METRICS =====

from prometheus_client import (
    Counter, Histogram, Gauge, Summary,
    generate_latest, CollectorRegistry,
    start_http_server
)
from functools import wraps
import time

class MetricsCollector:
    """Production-grade metrics collection"""
    
    def __init__(self):
        self.registry = CollectorRegistry()
        self._setup_metrics()
    
    def _setup_metrics(self):
        """Define all metrics"""
        
        # Request metrics
        self.requests_total = Counter(
            'requests_total',
            'Total requests',
            ['method', 'endpoint', 'status'],
            registry=self.registry
        )
        
        self.request_duration = Histogram(
            'request_duration_seconds',
            'Request duration',
            ['endpoint'],
            buckets=(0.001, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0),
            registry=self.registry
        )
        
        # Business metrics
        self.orders_created = Counter(
            'orders_created_total',
            'Orders created',
            ['status'],  # pending, completed, failed
            registry=self.registry
        )
        
        self.order_value = Histogram(
            'order_value_dollars',
            'Order values',
            buckets=(10, 50, 100, 500, 1000, 5000),
            registry=self.registry
        )
        
        # System metrics
        self.db_connections = Gauge(
            'db_connections_active',
            'Active database connections',
            registry=self.registry
        )
        
        self.cache_hits = Counter(
            'cache_hits_total',
            'Cache hits',
            registry=self.registry
        )
        
        self.cache_misses = Counter(
            'cache_misses_total',
            'Cache misses',
            registry=self.registry
        )
    
    def track_request(self, endpoint):
        """Decorator to track HTTP requests"""
        
        def decorator(f):
            @wraps(f)
            def wrapped(*args, **kwargs):
                start = time.time()
                
                try:
                    result = f(*args, **kwargs)
                    status = result[1] if isinstance(result, tuple) else 200
                    return result
                
                finally:
                    duration = time.time() - start
                    method = request.method
                    
                    self.request_duration.labels(endpoint=endpoint).observe(duration)
                    self.requests_total.labels(
                        method=method,
                        endpoint=endpoint,
                        status=status
                    ).inc()
            
            return wrapped
        
        return decorator
    
    def get_metrics(self):
        """Return metrics in Prometheus format"""
        
        return generate_latest(self.registry)

# Usage
metrics = MetricsCollector()

@app.route('/api/orders', methods=['POST'])
@metrics.track_request('/api/orders')
def create_order():
    """Create order with automatic metrics"""
    
    order = process_order(request.json)
    
    # Track business metric
    metrics.orders_created.labels(status='completed').inc()
    metrics.order_value.observe(order.total_value)
    
    return {'order_id': order.id}

@app.route('/metrics', methods=['GET'])
def prometheus_metrics():
    """Prometheus scrapes here"""
    
    return metrics.get_metrics()

# Start metrics server (optional, on different port)
if __name__ == '__main__':
    start_http_server(8000)  # Metrics on :8000
    app.run(port=5000)       # App on :5000

# Benefits:
# âœ… Comprehensive metrics
# âœ… Business metrics tracked
# âœ… System metrics tracked
# âœ… Automatic request tracking
# âœ… Production-ready
```

---

## ğŸ’¡ Mini Project: "Build Metrics Dashboard"

### Phase 1: Basic Metrics â­

**Requirements:**
- Prometheus setup
- Collect basic metrics (requests, latency, errors)
- Prometheus queries
- Basic alerting

---

### Phase 2: Grafana Dashboard â­â­

**Requirements:**
- Grafana visualization
- Multi-panel dashboard
- Real-time updates
- Historical trending

---

### Phase 3: Production Setup â­â­â­

**Requirements:**
- Multi-service monitoring
- Custom business metrics
- Alert rules
- Retention policies

---

## âš–ï¸ Metrics vs Logs vs Traces

| Aspect | Metrics | Logs | Traces |
|--------|---------|------|--------|
| **Data** | Numbers | Text | Spans |
| **Storage** | Small | Large | Medium |
| **Query** | Fast | Slow | Medium |
| **Purpose** | Trending | Debugging | Path tracking |

---

## âŒ Common Mistakes

### Mistake 1: Cardinality Explosion

```python
# âŒ Label per user (infinite cardinality!)
requests_total.labels(user_id=user_id).inc()
# Creates 1 metric per user = MILLIONS

# âœ… Pre-aggregate or summarize
requests_total.labels(endpoint='/api').inc()
# Only a few endpoints = manageable
```

### Mistake 2: Too Short Retention

```python
# âŒ Keep only 1 day of data
# Can't see weekly trends

# âœ… Keep historical data (or downsample)
# 15 days high resolution
# 90 days downsampled
# Enables trend analysis
```

### Mistake 3: Forgetting Business Metrics

```python
# âŒ Only system metrics (CPU, memory)
# Can't see business impact

# âœ… Track business metrics too
# Orders created
# Revenue
# User signups
# Both system AND business
```

---

## ğŸ“š Additional Resources

**Prometheus:**
- [Prometheus](https://prometheus.io/)
- [PromQL Tutorial](https://prometheus.io/docs/prometheus/latest/querying/basics/)

**Grafana:**
- [Grafana](https://grafana.com/)
- [Dashboard Templates](https://grafana.com/grafana/dashboards/)

**Metrics:**
- [Metrics Design](https://prometheus.io/docs/practices/instrumentation/)
- [Cardinality](https://prometheus.io/docs/prometheus/latest/querying/cardinality/)


---

## ğŸ¯ Before You Leave

**Can you answer these?**

1. **Counter vs gauge?**
   - Answer: Counter only up; gauge up/down

2. **Cardinality explosion?**
   - Answer: Too many label combinations = storage explosion

3. **Prometheus pull vs push?**
   - Answer: Prometheus pulls metrics from targets

4. **PromQL aggregation?**
   - Answer: sum, avg, rate, histogram_quantile

5. **When to use metrics vs logs?**
   - Answer: Metrics for trends; logs for debugging

**If you got these right, you're ready for the next topic!** âœ…

---

## ğŸ¤£ Closing Thoughts

> **Engineer:** "I'll just add a few metrics for debugging"
>
> **Later:** 50 metrics per endpoint
>
> **Even later:** 100 metrics per endpoint
>
> **Much later:** MILLIONS of metrics
>
> **Prometheus:** "Storage full!"
>
> **Engineer:** "I'll add cardinality limits"
>
> **Then:** All queries return "too many metrics"
>
> **Everyone:** "Metrics: helping you see nothing" ğŸ“Š

---

[â† Back to Main](../README.md) | [Previous: Logging, Monitoring & Observability](44-logging-monitoring-observability.md) | [Next: Tracing (Jaeger, OpenTelemetry)](46-tracing-jaeger.md)

---

**Last Updated:** November 11, 2025  
**Difficulty:** â­â­â­ Intermediate-Advanced (observability)  
**Time to Read:** 26 minutes  
**Time to Implement:** 4-7 hours per phase  

---

*Metrics: Turning data into understanding, one dashboard at a time.* ğŸš€