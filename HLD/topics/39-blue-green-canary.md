# 39. Blue-Green & Canary Deployments

Blue-Green deployment: you have two identical environments. Deploy to the green one while blue serves traffic. If green works, switch traffic. If green fails, users never notice. Sounds perfect until you realize it's twice the infrastructure cost. Canary deployment: deploy to 1% of users first. If it breaks, only 1% suffer. Then you have to explain to those 1% why they got the broken version. Welcome to modern deployments! ğŸš€ğŸ¤

[â† Back to Main](../README.md) | [Previous: Disaster Recovery](38-disaster-recovery.md) | [Next: Chaos Engineering](40-chaos-engineering.md)

---

## ğŸ¯ Quick Summary

**Blue-Green Deployment** maintains two identical environments (blue live, green staging). Deploy new version to green, test fully, switch traffic instantly. Zero downtime, instant rollback. Cost: 2x infrastructure. **Canary Deployment** rolls out to small percentage (1-5%) first, monitor, gradually increase. Catches bugs before hitting all users. Cost: low, but slower rollout. Netflix uses canaries, Amazon uses blue-green for critical services. Trade-off: cost vs safety vs rollout speed.

Think of it as: **Blue-Green = Safety Switch, Canary = Gradual Testing**

---

## ğŸŒŸ Beginner Explanation

### Deployment Strategies

```
TRADITIONAL DEPLOYMENT (Rolling):

V1 running on 10 servers
â”œâ”€ Stop server 1
â”œâ”€ Deploy V2 to server 1
â”œâ”€ Start server 1 (now V2)
â”œâ”€ Stop server 2
â”œâ”€ Deploy V2 to server 2
â”œâ”€ ... repeat for all servers

Problem:
â”œâ”€ Mixed V1 and V2 during deployment
â”œâ”€ API changes break things
â”œâ”€ If V2 broken: Already deployed to 5 servers
â”œâ”€ Slow rollback (must re-deploy V1)

Timeline:
T=0: V1 only
T=1: 1 V2, 9 V1 (mixed!)
T=5: 5 V2, 5 V1 (mixed!)
T=10: V2 only
â””â”€ 10 minutes mixed state


BLUE-GREEN DEPLOYMENT:

Blue environment (V1 running):
â”œâ”€ 10 servers running V1
â”œâ”€ Handling all traffic
â””â”€ Production

Green environment (V2 preparing):
â”œâ”€ 10 servers (identical setup)
â”œâ”€ Deploy V2 to all
â”œâ”€ Test fully
â”œâ”€ Staging (no traffic)

Switch:
â”œâ”€ All tests pass
â”œâ”€ Switch load balancer
â”œâ”€ Traffic: Blue â†’ Green instantly
â””â”€ Green now production

Timeline:
T=0: Blue=V1 (100%), Green=V1 (0%)
T=5: Blue=V1 (100%), Green=V2 ready (0%)
T=5.001: Blue=V1 (0%), Green=V2 (100%) â†’ Instant!
â””â”€ No mixed state!

Rollback:
â”œâ”€ V2 broken? No problem
â”œâ”€ Switch back: Green â†’ Blue instantly
â””â”€ Back to V1 in 1 second!


CANARY DEPLOYMENT:

V1 running on 100 servers
â”œâ”€ Deploy V2 to 1 server (canary)
â”œâ”€ Route 1% traffic to canary
â”œâ”€ Monitor metrics
â”œâ”€ No errors? Increase to 5%
â”œâ”€ No errors? Increase to 25%
â”œâ”€ No errors? Increase to 100%

Timeline:
T=0: 100% V1
T=1: 99% V1, 1% V2 (canary)
T=2: 95% V1, 5% V2 (if canary healthy)
T=5: 75% V1, 25% V2 (if canary healthy)
T=10: 0% V1, 100% V2 (if canary healthy)

Benefits:
âœ… Catches bugs before mass deployment
âœ… Gradual rollout
âœ… Easy rollback (just shift traffic)
âœ… Normal infrastructure cost
âŒ Slower than blue-green
```

### Comparison

```
DEPLOYMENT STRATEGY COMPARISON:

Rolling Update:
â”œâ”€ Cost: 1x (reuse servers)
â”œâ”€ Speed: Slow (gradual)
â”œâ”€ Risk: Medium (mixed versions)
â”œâ”€ Rollback: Slow (must re-deploy)
â””â”€ Use case: Low-risk updates

Blue-Green:
â”œâ”€ Cost: 2x (dual infrastructure)
â”œâ”€ Speed: Instant (switch at once)
â”œâ”€ Risk: Low (no mixed state)
â”œâ”€ Rollback: Instant (switch back)
â””â”€ Use case: High-risk, critical services

Canary:
â”œâ”€ Cost: 1x (gradual shift)
â”œâ”€ Speed: Medium (gradual)
â”œâ”€ Risk: Low (catches bugs early)
â”œâ”€ Rollback: Fast (shift traffic back)
â””â”€ Use case: Most services (default!)

Shadow:
â”œâ”€ Cost: 1.5x (duplicate traffic)
â”œâ”€ Speed: N/A (testing only)
â”œâ”€ Risk: None (shadow doesn't serve)
â”œâ”€ Use case: Testing major changes
```


### Canary Monitoring

```
CANARY METRICS (Watch for):

Error Rate:
â”œâ”€ Canary error rate > 1%? â†’ Rollback!
â”œâ”€ Example: 0.1% for V1, 1.5% for V2
â””â”€ Stop deploying immediately

Latency:
â”œâ”€ Canary p99 latency > V1 by 50%? â†’ Rollback!
â”œâ”€ Example: V1 = 100ms, V2 = 200ms
â””â”€ Users notice slowness

Memory Usage:
â”œâ”€ Canary memory spike > 30%? â†’ Rollback!
â”œâ”€ Example: Memory leak in V2
â””â”€ Servers crash soon

CPU Usage:
â”œâ”€ Canary CPU > 80%? â†’ Rollback!
â”œâ”€ Example: Inefficient algorithm
â””â”€ Servers struggle

Customer Complaints:
â”œâ”€ Spike in support tickets? â†’ Investigate
â”œâ”€ Real user impact, not just metrics
â””â”€ Human judgment matters

Alerting:
â”œâ”€ If ANY metric bad: Alert engineer
â”œâ”€ Don't wait for "all clear"
â”œâ”€ Err on side of caution
â””â”€ Can always fix and re-deploy
```

---

## ğŸ”¬ Advanced Explanation

### Blue-Green Architecture

```
SETUP:

Load Balancer (DNS):
â”œâ”€ Blue pool: 10 servers (V1)
â”œâ”€ Green pool: 10 servers (V1 initially)
â””â”€ Initially routes to Blue

Pipeline:

1. Deploy stage:
   â”œâ”€ Build V2 image
   â”œâ”€ Start servers in Green pool
   â”œâ”€ Deploy V2 to Green
   â””â”€ Green now running V2

2. Test stage:
   â”œâ”€ Run smoke tests
   â”œâ”€ Run integration tests
   â”œâ”€ Check health endpoints
   â”œâ”€ Load test Green
   â””â”€ All must pass

3. Switch stage:
   â”œâ”€ Update load balancer config
   â”œâ”€ Change to route to Green
   â”œâ”€ Blue now idle
   â””â”€ V2 now serving all traffic

4. Verify stage:
   â”œâ”€ Monitor metrics
   â”œâ”€ Check user reports
   â”œâ”€ If all good: Done!
   â”œâ”€ If problem: Switch back to Blue
   â””â”€ Rollback in seconds

5. Cleanup stage:
   â”œâ”€ After N hours (24h) of Green stability
   â”œâ”€ Stop Blue servers
   â”œâ”€ Prepare Blue for next deployment
   â””â”€ Now Blue and Green swap roles


FAILURE SCENARIOS:

Test fails:
â”œâ”€ Fix code
â”œâ”€ Rebuild V2
â”œâ”€ Re-test
â”œâ”€ Blue still running (users unaffected)
â””â”€ Zero impact

Production issue after switch:
â”œâ”€ Switch back: Green â†’ Blue instantly
â”œâ”€ V1 now serving traffic
â”œâ”€ Customers likely didn't notice
â””â”€ Investigate issue, fix, try again
```

### Canary Implementation

```
CANARY DEPLOYMENT PROCESS:

Phase 1: Canary (1-5% traffic)
â”œâ”€ Deploy V2 to 1-2 servers
â”œâ”€ Route 1-5% traffic to V2
â”œâ”€ Monitor for 30 minutes
â”œâ”€ Thresholds:
â”‚  â”œâ”€ Error rate < 0.5%
â”‚  â”œâ”€ Latency increase < 20%
â”‚  â”œâ”€ CPU stable
â”‚  â””â”€ Memory stable
â””â”€ If passes: Continue

Phase 2: Early (10-25% traffic)
â”œâ”€ Deploy V2 to more servers
â”œâ”€ Route 10-25% traffic to V2
â”œâ”€ Monitor for 1 hour
â”œâ”€ Same thresholds
â””â”€ If passes: Continue

Phase 3: Main (50% traffic)
â”œâ”€ Deploy V2 to half servers
â”œâ”€ Route 50% traffic
â”œâ”€ Monitor for 2 hours
â”œâ”€ Broader metrics check
â””â”€ If passes: Continue

Phase 4: Full (100% traffic)
â”œâ”€ Deploy V2 to all servers
â”œâ”€ Route 100% traffic
â”œâ”€ Monitor for 24 hours
â”œâ”€ High alert state
â””â”€ If stable: Deployment complete


ROLLBACK CRITERIA:

Automatic rollback if:
â”œâ”€ Error rate > 1% (vs baseline)
â”œâ”€ P99 latency > baseline Ã— 1.5
â”œâ”€ CPU > 85%
â”œâ”€ Memory > 85%
â”œâ”€ Disk fill rate > 50%/hour
â””â”€ Any critical error in logs

Manual rollback if:
â”œâ”€ Customer complaints spike
â”œâ”€ Unexpected behavior
â”œâ”€ "This looks suspicious"
â””â”€ Better safe than sorry!
```

### Traffic Splitting

```
IMPLEMENTATION METHODS:

Method 1: Weighted Load Balancer
â”œâ”€ Load balancer has weight config
â”œâ”€ Blue: 99%, Green: 1%
â”œâ”€ Gradually adjust weights
â””â”€ Examples: Nginx, HAProxy

Method 2: Service Mesh (Istio)
â”œâ”€ VirtualService rules
â”œâ”€ Can route by header/cookie
â”œâ”€ A/B testing: Route by user ID
â”œâ”€ Geographic: Route by location
â””â”€ Advanced traffic splitting

Method 3: Feature Flags
â”œâ”€ Both versions running
â”œâ”€ Flag controls which code path
â”œâ”€ Can toggle instantly
â”œâ”€ Gradual feature rollout
â””â”€ No deployment needed

Method 4: DNS
â”œâ”€ Two DNS records: blue, green
â”œâ”€ Update weight in DNS
â”œâ”€ Slower propagation (TTL)
â”œâ”€ Not ideal for fast rollback
â””â”€ But used in some systems
```

---

## ğŸ Python Code Example

### âŒ Without Safe Deployment (Big Bang)

```python
# ===== BIG BANG DEPLOYMENT (RISKY) =====

import subprocess

def deploy_v2():
    """Deploy V2 to all servers at once"""
    
    servers = [f"server-{i}.prod.com" for i in range(1, 11)]
    
    for server in servers:
        print(f"Deploying to {server}...")
        
        # Stop server
        subprocess.run(['ssh', server, 'systemctl stop app'])
        
        # Deploy V2
        subprocess.run(['ssh', server, 'git pull && python setup.py install'])
        
        # Start server
        subprocess.run(['ssh', server, 'systemctl start app'])
    
    print("All servers updated to V2")

# Problem:
# âŒ All servers updated simultaneously
# âŒ If V2 broken: All users see error
# âŒ Must manually fix all 10 servers
# âŒ Slow rollback
# âŒ No testing before production
```

### âœ… Blue-Green Deployment

```python
# ===== BLUE-GREEN DEPLOYMENT =====

import subprocess
import time

class BlueGreenDeployment:
    """Blue-green deployment manager"""
    
    def __init__(self):
        self.blue_servers = [f"blue-{i}.prod.com" for i in range(1, 11)]
        self.green_servers = [f"green-{i}.prod.com" for i in range(1, 11)]
        self.load_balancer = "lb.prod.com"
        self.active_pool = "blue"  # Currently serving traffic
    
    def deploy_to_green(self):
        """Deploy V2 to green environment"""
        
        print("1. Deploying to green environment...")
        
        for server in self.green_servers:
            print(f"  Deploying to {server}...")
            subprocess.run(['ssh', server, 'git pull && python setup.py install'])
        
        print("âœ“ Green deployment complete")
    
    def test_green(self):
        """Test green environment before switching"""
        
        print("2. Testing green environment...")
        
        # Smoke tests
        for server in self.green_servers:
            response = subprocess.run(
                ['curl', '-f', f'http://{server}:8000/health'],
                capture_output=True
            )
            if response.returncode != 0:
                print(f"âœ— Health check failed on {server}")
                return False
        
        print("âœ“ All health checks passed")
        
        # Load test
        print("  Load testing...")
        result = subprocess.run([
            'ab', '-n', '10000', '-c', '100',
            f'http://{self.green_servers[0]}:8000/api/test'
        ], capture_output=True)
        
        print("âœ“ Load test completed")
        
        return True
    
    def switch_traffic(self):
        """Switch traffic from blue to green"""
        
        print("3. Switching traffic...")
        
        # Update load balancer
        config = f"""
        upstream app {{
            server {self.green_servers[0]}:8000;
            # ... all green servers
        }}
        """
        
        # Update load balancer config
        with open('/tmp/lb-config.conf', 'w') as f:
            f.write(config)
        
        subprocess.run(['scp', '/tmp/lb-config.conf', f'{self.load_balancer}:/etc/nginx/'])
        subprocess.run(['ssh', self.load_balancer, 'systemctl reload nginx'])
        
        self.active_pool = "green"
        print("âœ“ Traffic switched to green")
    
    def verify_traffic(self):
        """Verify traffic is flowing correctly"""
        
        print("4. Verifying traffic...")
        
        time.sleep(5)  # Wait for traffic to stabilize
        
        # Check error rate
        errors = 0
        total = 100
        
        for i in range(total):
            response = subprocess.run(
                ['curl', '-s', f'http://{self.load_balancer}/api/test'],
                capture_output=True
            )
            if response.returncode != 0:
                errors += 1
        
        error_rate = errors / total
        
        if error_rate > 0.01:  # > 1% error
            print(f"âœ— Error rate too high: {error_rate:.2%}")
            return False
        
        print(f"âœ“ Error rate acceptable: {error_rate:.2%}")
        return True
    
    def rollback_if_needed(self):
        """Rollback to blue if issues detected"""
        
        print("5. Checking for issues...")
        
        if not self.verify_traffic():
            print("âœ— Issues detected, rolling back...")
            
            # Switch back to blue
            subprocess.run(['ssh', self.load_balancer, 'systemctl reload nginx'])
            
            self.active_pool = "blue"
            print("âœ“ Rolled back to blue")
            return False
        
        print("âœ“ All checks passed, staying on green")
        return True
    
    def deploy(self):
        """Execute full blue-green deployment"""
        
        print("\n=== Blue-Green Deployment ===")
        print(f"Current active: {self.active_pool}")
        
        # Deploy
        self.deploy_to_green()
        
        # Test
        if not self.test_green():
            print("âœ— Testing failed, aborting deployment")
            return False
        
        # Switch
        self.switch_traffic()
        
        # Verify
        if not self.rollback_if_needed():
            return False
        
        print("\nâœ“ Deployment successful!")
        return True

# Usage
deployment = BlueGreenDeployment()
deployment.deploy()

# Benefits:
# âœ… No mixed V1/V2 state
# âœ… Instant switch
# âœ… Easy rollback (1 second)
# âœ… Full testing before switch
# âœ… Zero perceived downtime
```

### âœ… Canary Deployment

```python
# ===== CANARY DEPLOYMENT =====

import time
import random

class CanaryDeployment:
    """Canary deployment manager"""
    
    def __init__(self):
        self.servers = [f"server-{i}.prod.com" for i in range(1, 101)]
        self.load_balancer = "lb.prod.com"
        self.metrics = {}
    
    def deploy_canary(self):
        """Deploy V2 to canary servers (1-2 servers)"""
        
        print("1. Deploying canary (1 server)...")
        
        canary_server = self.servers[0]
        print(f"  Deploying to {canary_server}...")
        
        import subprocess
        subprocess.run(['ssh', canary_server, 'git pull && python setup.py install'])
        
        print("âœ“ Canary deployed")
        return [canary_server]
    
    def route_traffic(self, percentage, canary_servers):
        """Route X% traffic to canary"""
        
        print(f"2. Routing {percentage}% traffic to canary...")
        
        # Update load balancer weights
        print(f"âœ“ {percentage}% traffic routed to canary")
    
    def monitor_canary(self, duration_minutes=5):
        """Monitor canary metrics"""
        
        print(f"3. Monitoring canary for {duration_minutes} minutes...")
        
        start_time = time.time()
        
        while time.time() - start_time < duration_minutes * 60:
            # Get metrics
            error_rate = random.uniform(0.001, 0.002)  # Mock: 0.1-0.2%
            p99_latency = random.uniform(90, 110)  # Mock: 90-110ms
            
            print(f"  Error rate: {error_rate:.2%}, P99: {p99_latency:.0f}ms")
            
            # Check thresholds
            if error_rate > 0.01:  # > 1% error
                print(f"âœ— Error rate too high: {error_rate:.2%}")
                return False
            
            if p99_latency > 150:  # > 150ms
                print(f"âœ— Latency too high: {p99_latency:.0f}ms")
                return False
            
            time.sleep(10)
        
        print("âœ“ Canary monitoring passed")
        return True
    
    def gradually_deploy(self):
        """Gradual deployment: canary â†’ 10% â†’ 50% â†’ 100%"""
        
        print("\n=== Canary Deployment ===\n")
        
        canary_servers = self.deploy_canary()
        
        # Phase 1: Canary (1%)
        self.route_traffic(1, canary_servers)
        if not self.monitor_canary(duration_minutes=5):
            print("âœ— Canary failed, rolling back")
            return False
        
        # Phase 2: Early (10%)
        print("\nPhase 2: Increasing to 10%...")
        servers_10 = self.servers[:10]
        for s in servers_10:
            print(f"  Deploying to {s}...")
        self.route_traffic(10, servers_10)
        if not self.monitor_canary(duration_minutes=10):
            print("âœ— Phase 2 failed, rolling back")
            return False
        
        # Phase 3: Main (50%)
        print("\nPhase 3: Increasing to 50%...")
        servers_50 = self.servers[:50]
        for s in servers_50[10:]:
            print(f"  Deploying to {s}...")
        self.route_traffic(50, servers_50)
        if not self.monitor_canary(duration_minutes=15):
            print("âœ— Phase 3 failed, rolling back")
            return False
        
        # Phase 4: Full (100%)
        print("\nPhase 4: Increasing to 100%...")
        for s in self.servers[50:]:
            print(f"  Deploying to {s}...")
        self.route_traffic(100, self.servers)
        if not self.monitor_canary(duration_minutes=30):
            print("âœ— Phase 4 failed, rolling back")
            return False
        
        print("\nâœ“ Canary deployment successful!")
        return True

# Usage
canary = CanaryDeployment()
canary.gradually_deploy()

# Benefits:
# âœ… Gradual rollout (catches bugs early)
# âœ… Only 1% affected if broken
# âœ… Normal infrastructure cost
# âœ… Can rollback easily
# âŒ Slower than blue-green
```

---

## ğŸ’¡ Mini Project: "Implement Safe Deployment"

### Phase 1: Blue-Green â­

**Requirements:**
- Two environments setup
- Deploy to inactive
- Test before switch
- Instant rollback

---

### Phase 2: Canary â­â­

**Requirements:**
- Canary phase (1%)
- Gradual increase
- Metric monitoring
- Automatic rollback

---

### Phase 3: Advanced â­â­â­

**Requirements:**
- A/B testing
- Feature flags
- Shadow traffic
- Multi-region

---

## âš–ï¸ Deployment Strategies Comparison

| Strategy | Risk | Speed | Cost | Rollback |
|----------|------|-------|------|----------|
| **Rolling** | High | Slow | 1x | Slow |
| **Blue-Green** | Low | Instant | 2x | Instant |
| **Canary** | Low | Medium | 1x | Fast |
| **Shadow** | None | N/A | 1.5x | N/A |

---

## âŒ Common Mistakes

### Mistake 1: No Automated Tests

```python
# âŒ Deploy and hope
deploy_to_green()
switch_traffic()
# What if V2 broken?

# âœ… Comprehensive testing
deploy_to_green()
run_smoke_tests()
run_integration_tests()
run_load_tests()
check_health_endpoints()
# Only then switch
```

### Mistake 2: Canary Too Small

```python
# âŒ 0.1% canary
# Might miss bugs
# 1 user gets broken version

# âœ… 2-5% canary
# More realistic traffic
# Catches more bugs
# 20-50 users maximum impact
```

### Mistake 3: No Automatic Rollback

```python
# âŒ Monitor manually
# Humans miss issues
# Takes 10 minutes to notice

# âœ… Automatic rollback
# Metrics monitored continuously
# Rollback in < 1 minute
# Humans get alert
```

---

## ğŸ“š Additional Resources

**Deployment Strategies:**
- [Blue-Green Deployment](https://martinfowler.com/bliki/BlueGreenDeployment.html)
- [Canary Releases](https://martinfowler.com/bliki/CanaryRelease.html)

**Tools:**
- [Flagger (Canary automation)](https://flagger.app/)
- [Spinnaker (Deployment platform)](https://www.spinnaker.io/)


---

## ğŸ¯ Before You Leave

**Can you answer these?**

1. **Blue-green vs canary?**
   - Answer: Blue-green instant, canary gradual

2. **When to use blue-green?**
   - Answer: Critical services, high risk

3. **When to use canary?**
   - Answer: Most services, default choice

4. **Canary success criteria?**
   - Answer: Error rate, latency, resource usage

5. **How to rollback?**
   - Answer: Switch traffic/feature flag

**If you got these right, you're ready for the next topic!** âœ…

---

## ğŸ¤£ Closing Thoughts

> **Manager:** "Deploy the new version!"
>
> **Engineer:** "OK, deploying to blue..."
>
> **5 minutes later:** "Testing... all good!"
>
> **Switch:** Blue â†’ Green (instant)
>
> **2 minutes later:** "OH NO, ERRORS!"
>
> **Switch:** Green â†’ Blue (instant)
>
> **Manager:** "What happened?"
>
> **Engineer:** "A feature worked great in staging but broke in production"
>
> **Everyone:** "Classic!" ğŸ¤·

---

[â† Back to Main](../README.md) | [Previous: Disaster Recovery](38-disaster-recovery.md) | [Next: Chaos Engineering](40-chaos-engineering.md)

---

**Last Updated:** November 11, 2025  
**Difficulty:** â­â­â­ Intermediate-Advanced (DevOps)  
**Time to Read:** 25 minutes  
**Time to Implement:** 5-8 hours per phase  

---

*Blue-Green & Canary: Making deployments safe, predictable, and rollback-friendly.* ğŸš€