# 35. Failover & Replication Strategies

Replication is keeping copies of your data so when one fails, you have backups. Failover is automatically switching to the backup. Together they make your system survive catastrophes. Except when replication is 5 seconds behind and your failover is too slow. Then everyone loses data and you update your resume. Welcome to distributed systems! ğŸ“‹â¡ï¸ğŸ’¥

[â† Back to Main](../README.md) | [Previous: Heartbeats & Health Checks](34-heartbeats-health-checks.md) | [Next: Circuit Breakers â†’](36-circuit-breakers.md)

---

## ğŸ¯ Quick Summary

**Replication** copies data across multiple servers (master-slave, peer-to-peer). **Failover** automatically switches to replica when primary fails. Without: one server dies, data lost. With: primary dies, replica takes over, zero downtime. Trade-offs: consistency (eventual vs strong), complexity (coordination), latency (sync vs async replication). Netflix uses active-active replication across regions. Amazon has auto-failover minutes. Critical for high availability systems.

Think of it as: **Replication = Safety Net, Failover = Automatic Rescue**

---

## ğŸŒŸ Beginner Explanation

### Replication Types

**MASTER-SLAVE (Primary-Replica):**

```
Write (Master):
â”œâ”€ Client writes to master
â”œâ”€ Master processes transaction
â”œâ”€ Data stored locally
â”œâ”€ Transaction committed
â””â”€ Return "success" to client

Replication (Asynchronous):
â”œâ”€ Master broadcasts: "New row added"
â”œâ”€ Slave 1: Receives, applies locally
â”œâ”€ Slave 2: Receives, applies locally
â”œâ”€ Slave 3: Receives, applies locally
â””â”€ Takes 1-5 seconds (lag!)

Read (Slave):
â”œâ”€ Client reads from slave
â”œâ”€ Faster (no writes)
â”œâ”€ Might be stale (if replication lagging)
â””â”€ "Eventually consistent"

Pros:
âœ… Write scaling (one master)
âœ… Read scaling (many slaves)
âœ… Simple coordination (master decides)
âœ… Fast writes (master doesn't wait)

Cons:
âŒ If master dies: Data loss (unreplicated writes)
âŒ Slaves can be stale
âŒ Master bottleneck for writes
âŒ Write throughput limited by master
```

**PEER-TO-PEER (Multi-Master):**

```
Write (Any Node):
â”œâ”€ Client writes to Node A
â”œâ”€ Node A processes transaction
â”œâ”€ Node A broadcasts: "New row"
â””â”€ Return success (immediately!)

Replication (Asynchronous):
â”œâ”€ Node B: Receives, applies
â”œâ”€ Node C: Receives, applies
â”œâ”€ Node D: Receives, applies
â””â”€ All have same data (eventually)

Meanwhile:
â”œâ”€ Client writes to Node B
â”œâ”€ Node B processes transaction
â”œâ”€ Node B broadcasts
â””â”€ Nodes A, C, D apply

Result:
â”œâ”€ All nodes have all writes
â”œâ”€ Can write to any node
â”œâ”€ Highly available

Pros:
âœ… No single point of failure
âœ… Write to any node
âœ… Any node can fail
âœ… Highly available

Cons:
âŒ Conflict resolution (two writes conflict?)
âŒ Complex coordination
âŒ Slower (need quorum)
âŒ Consistency harder
```

### Failover Process

```
MANUAL FAILOVER (Old way):

T=0: Master dies
â”œâ”€ System down
â””â”€ Users see errors

T=5: Monitoring detects failure
â”œâ”€ Sends alert
â””â”€ PagerDuty rings phone

T=10: On-call engineer wakes up
â”œâ”€ Reads alert
â”œâ”€ Checks database
â””â”€ "Master is dead"

T=15: Engineer SSH to slave
â”œâ”€ Runs: "PROMOTE REPLICA"
â”œâ”€ Slave becomes new master
â””â”€ Sends update to application

T=20: Application reconnects to new master
â”œâ”€ Resumes accepting writes
â””â”€ System back up!

Downtime: 20 minutes!
Data loss: Writes in last 5 minutes lost!


AUTOMATIC FAILOVER (Modern way):

T=0: Master dies
â”œâ”€ Stops responding to health checks
â””â”€ Heartbeat stops

T=5: Health check detects failure
â”œâ”€ Master marked "down"
â”œâ”€ Triggers automatic failover
â””â”€ Monitoring alerts

T=5.5: Failover logic runs
â”œâ”€ Check: Is slave up to date?
â”œâ”€ Check: Can slave be promoted?
â”œâ”€ Promote slave to master
â”œâ”€ Update DNS/service discovery
â””â”€ Application auto-reconnects (no code change!)

T=6: System back up!
â”œâ”€ Failover completed
â”œâ”€ Application resumed
â””â”€ New master accepting writes

Downtime: ~1 second!
Data loss: None (if using synchronous replication)!
```

### Replication Lag Problem

```
SYNCHRONOUS REPLICATION (Safe but slow):

Master write:
â”œâ”€ Write data
â”œâ”€ Wait for slave confirmation
â”œâ”€ Slave received and stored
â”œâ”€ Return "success" to client

Latency: 50-100ms (waiting for network)

Safety:
âœ… Slave always in sync
âœ… Zero data loss
âŒ Write throughput limited (must wait)


ASYNCHRONOUS REPLICATION (Fast but risky):

Master write:
â”œâ”€ Write data
â”œâ”€ Return "success" immediately
â”œâ”€ Queue write for replication
â”œâ”€ Slave catches up (later)

Latency: < 1ms (no wait!)

Risk:
âŒ Master dies before replication
â”œâ”€ Writes lost!
â”œâ”€ Slave doesn't have them
â””â”€ Data inconsistency

Example:
T=0: Write "order created"
T=0.1: Return success
T=1: Master crashes (before replicating)
T=2: Failover to slave
T=3: Slave doesn't have order! (lost)


SEMI-SYNCHRONOUS REPLICATION (Balance):

Master write:
â”œâ”€ Write data
â”œâ”€ Wait for at least 1 slave confirmation
â”œâ”€ Return "success"
â”œâ”€ Other slaves catch up asynchronously

Latency: 20-50ms (wait for 1 slave)

Safety:
âœ… At least 2 copies (master + 1 slave)
âœ… Tolerate 1 node failure
âœ… Lower latency than full sync
âŒ 2nd slave might be behind
```

---

## ğŸ”¬ Advanced Explanation

### Failover Strategies

```
ACTIVE-PASSIVE (One way):

Active (master): Accepts all traffic
â”œâ”€ Processes writes
â”œâ”€ Serves reads
â””â”€ Single point of failure

Passive (slave): Idle, waiting
â”œâ”€ Replicates data
â”œâ”€ Can't process traffic
â”œâ”€ Resources wasted

Failover:
â”œâ”€ Master dies
â”œâ”€ Promote slave to master
â”œâ”€ Slave becomes active
â””â”€ Old master was passive, so no conflict

Tradeoff:
âœ… Simple (one active master)
âœ… Clear consistency model
âœ… Easy conflict resolution (no conflicts!)
âŒ Idle slave resources wasted
âŒ Failover slightly slower (promotion takes time)


ACTIVE-ACTIVE (Both ways):

Active 1: Accepts traffic
â”œâ”€ Processes writes
â”œâ”€ Serves reads
â””â”€ Replicates to Active 2

Active 2: Accepts traffic
â”œâ”€ Processes writes
â”œâ”€ Serves reads
â””â”€ Replicates to Active 1

Failover:
â”œâ”€ Node 1 dies
â”œâ”€ Node 2 continues serving
â”œâ”€ No failover needed!
â””â”€ Other nodes route to Node 2

Benefits:
âœ… No idle resources (both working)
âœ… Both serve reads
âœ… Natural load distribution
âŒ Complexity (both writing)
âŒ Conflict resolution needed (if both write same data)

Example conflict:
T=0: Node A writes row:  name="Alice"
T=0: Node B writes same row: name="Bob"
T=1: Replication arrives at opposite node
T=1: Both nodes see conflict!
T=2: Conflict resolution: Last write wins (or merge)
```

### Consistency Models

```
STRONG CONSISTENCY (ACID):

All reads see latest writes:

Write: user.name = "Alice"
â”œâ”€ Stored on master
â”œâ”€ Synchronously replicated to all slaves
â””â”€ Return "success"

Read (any node):
â”œâ”€ Always returns: name = "Alice"
â”œâ”€ All nodes have latest
â””â”€ Consistent view

Pros:
âœ… Simple (no surprises)
âœ… Predictable
âœ… ACID transactions

Cons:
âŒ Slow (wait for replication)
âŒ Fails if replication down
âŒ Lower throughput


EVENTUAL CONSISTENCY:

Reads might see old writes (temporarily):

Write: user.name = "Alice"
â”œâ”€ Stored on master
â”œâ”€ Return "success"
â”œâ”€ Asynchronously replicate
â””â”€ Might take 5 seconds

Read from slave (1 second later):
â”œâ”€ Slave still has: name = "Bob" (old)
â”œâ”€ Returns stale data
â””â”€ Inconsistent!

But eventually:
â”œâ”€ Replication completes
â”œâ”€ Slave updates: name = "Alice"
â”œâ”€ Consistency achieved!

Pros:
âœ… Fast (don't wait)
âœ… High throughput
âœ… Survives replication delays

Cons:
âŒ Temporary inconsistency
âŒ Complex reasoning
âŒ Bugs if not handled


CAUSAL CONSISTENCY (Middle ground):

Related operations stay consistent:

Write 1: Create user (Alice)
Write 2: Create order for Alice

On read:
â”œâ”€ Might see order before user (inconsistent!)
â”œâ”€ But can't happen with causal consistency
â”œâ”€ If you see order, you've seen user

Pros:
âœ… Consistency for related operations
âœ… Better throughput than strong
âœ… More predictable than eventual

Cons:
âŒ Complex to implement
âŒ Still potential for unrelated inconsistency
```

### Handling Replication Lag

```
PROBLEM: Slave is 5 seconds behind

T=0: Write order: $100
T=1: Read from slave: $0 (old value!)
T=2: Display: "Order not found!"
T=5: Slave catches up
T=6: Read from slave: $100

User sees inconsistency!

SOLUTION 1: Read from master

Write order:
â””â”€ Write to master

Read order:
â””â”€ Read from master (always latest)

Downside:
âŒ Master becomes bottleneck
âŒ No read scaling


SOLUTION 2: Read-your-write consistency

Write order:
â”œâ”€ Write to master
â”œâ”€ Store write-token (version: 1000)
â””â”€ Return to client

Read order:
â”œâ”€ Send write-token to slave
â”œâ”€ Slave checks: "My version >= 1000?"
â”œâ”€ If yes: Serve from slave (caught up!)
â”œâ”€ If no: Wait or read from master
â””â”€ Client always sees writes

Pro:
âœ… Scales reads (if slave caught up)
âœ… Strong for user's own writes


SOLUTION 3: Sticky reads

Write order:
â”œâ”€ Write to master: 101
â””â”€ Return to client

Read order:
â”œâ”€ Route to same master (sticky)
â”œâ”€ Always see latest
â””â”€ Consistent!

Downside:
âŒ Can't load balance reads
âŒ If master slow: All reads slow
```

---

## ğŸ Python Code Example

### âŒ Without Replication (Single Point of Failure)

```python
# ===== WITHOUT REPLICATION =====

import psycopg2

# Single database server
db = psycopg2.connect("dbname=shop host=db1.example.com")

def create_order(user_id, items):
    """Create order on single server"""
    
    cursor = db.cursor()
    cursor.execute("""
        INSERT INTO orders (user_id, items, created_at)
        VALUES (%s, %s, NOW())
        RETURNING id
    """, (user_id, str(items)))
    
    order_id = cursor.fetchone()[0]
    db.commit()
    
    return order_id

# Problem:
# âŒ Single database server
# âŒ If db1 dies: Orders can't be created
# âŒ Data lost (no backup)
# âŒ No failover
# âŒ Single point of failure
```

### âœ… Master-Slave Replication

```python
# ===== MASTER-SLAVE REPLICATION =====

import psycopg2
import psycopg2.pool

# Connection pools for master and slave
master_pool = psycopg2.pool.SimpleConnectionPool(
    1, 10,
    "dbname=shop host=master.example.com user=admin"
)

slave_pool = psycopg2.pool.SimpleConnectionPool(
    1, 20,  # More slaves for read scaling
    "dbname=shop host=slave.example.com user=readonly"
)

def create_order(user_id, items):
    """Create order on master"""
    
    master_conn = master_pool.getconn()
    try:
        cursor = master_conn.cursor()
        cursor.execute("""
            INSERT INTO orders (user_id, items, created_at)
            VALUES (%s, %s, NOW())
            RETURNING id
        """, (user_id, str(items)))
        
        order_id = cursor.fetchone()[0]
        master_conn.commit()
        
        # Replication happens asynchronously
        # (slave catches up in background)
        
        return order_id
    
    finally:
        master_pool.putconn(master_conn)

def get_orders(user_id):
    """Read orders from slave (read scaling)"""
    
    slave_conn = slave_pool.getconn()
    try:
        cursor = slave_conn.cursor()
        cursor.execute("""
            SELECT * FROM orders
            WHERE user_id = %s
            ORDER BY created_at DESC
        """, (user_id,))
        
        return cursor.fetchall()
    
    finally:
        slave_pool.putconn(slave_conn)

# Benefits:
# âœ… Writes to master (consistent)
# âœ… Reads from slave (scalable)
# âœ… Replication asynchronous (fast)
# âœ… Handles 10x more reads
```

### âœ… Production Failover (Automatic)

```python
# ===== PRODUCTION FAILOVER (AUTOMATIC) =====

import psycopg2
from dataclasses import dataclass
from typing import Optional
import threading
import time

@dataclass
class DatabaseNode:
    name: str
    host: str
    port: int = 5432
    role: str = "replica"  # master or replica
    is_healthy: bool = True

class FailoverManager:
    """Manage failover between master and replicas"""
    
    def __init__(self):
        self.master: Optional[DatabaseNode] = None
        self.replicas: list[DatabaseNode] = []
        self.master_pool = None
        self.replica_pools = {}
    
    def add_master(self, name: str, host: str):
        """Register master database"""
        self.master = DatabaseNode(name, host, role="master")
        self.master_pool = self._create_pool(host)
    
    def add_replica(self, name: str, host: str):
        """Register replica database"""
        replica = DatabaseNode(name, host, role="replica")
        self.replicas.append(replica)
        self.replica_pools[name] = self._create_pool(host)
    
    def _create_pool(self, host: str):
        """Create connection pool"""
        return psycopg2.pool.SimpleConnectionPool(
            1, 10,
            f"dbname=shop host={host} user=app"
        )
    
    def health_check_master(self) -> bool:
        """Check if master is healthy"""
        
        try:
            conn = self.master_pool.getconn()
            cursor = conn.cursor()
            cursor.execute("SELECT 1")
            self.master_pool.putconn(conn)
            
            self.master.is_healthy = True
            return True
        
        except Exception as e:
            self.master.is_healthy = False
            print(f"Master health check failed: {e}")
            return False
    
    def write_to_master(self, query: str, params: tuple):
        """Write always goes to master"""
        
        if not self.master.is_healthy:
            raise Exception("Master is down, cannot write!")
        
        conn = self.master_pool.getconn()
        try:
            cursor = conn.cursor()
            cursor.execute(query, params)
            conn.commit()
            result = cursor.fetchone()
            return result
        
        finally:
            self.master_pool.putconn(conn)
    
    def read_from_replica(self, query: str, params: tuple):
        """Read from any healthy replica"""
        
        for replica in self.replicas:
            if not replica.is_healthy:
                continue
            
            try:
                pool = self.replica_pools[replica.name]
                conn = pool.getconn()
                cursor = conn.cursor()
                cursor.execute(query, params)
                result = cursor.fetchall()
                pool.putconn(conn)
                
                return result
            
            except Exception as e:
                print(f"Read from {replica.name} failed: {e}")
                replica.is_healthy = False
                continue
        
        raise Exception("All replicas down!")
    
    def promote_replica_to_master(self, replica_name: str):
        """Promote replica to master (failover)"""
        
        print(f"Promoting {replica_name} to master...")
        
        replica = next((r for r in self.replicas if r.name == replica_name), None)
        if not replica:
            raise Exception(f"Replica {replica_name} not found")
        
        # Get connection to replica
        pool = self.replica_pools[replica_name]
        conn = pool.getconn()
        
        try:
            cursor = conn.cursor()
            
            # Run promotion commands
            cursor.execute("SELECT pg_wal_replay_pause()")  # Pause replication
            cursor.execute("ALTER SYSTEM SET primary_conninfo = ''")  # Remove primary
            cursor.execute("SELECT pg_ctl_promote()")  # Promote to master
            
            conn.commit()
            print(f"âœ“ {replica_name} promoted to master")
            
            # Update in-memory state
            old_master = self.master
            self.master = replica
            self.master.role = "master"
            self.master.is_healthy = True
            
            # Remove from replicas list
            self.replicas.remove(replica)
            
            return True
        
        finally:
            pool.putconn(conn)
    
    def start_health_monitoring(self, interval_seconds=10):
        """Background thread to monitor health"""
        
        def monitor():
            while True:
                # Check master
                if not self.health_check_master():
                    print("âš  Master down! Initiating failover...")
                    
                    # Find best replica
                    best_replica = self.replicas[0]
                    
                    # Promote it
                    try:
                        self.promote_replica_to_master(best_replica.name)
                        print("âœ“ Failover completed!")
                    except Exception as e:
                        print(f"âœ— Failover failed: {e}")
                
                # Check replicas
                for replica in self.replicas:
                    try:
                        pool = self.replica_pools[replica.name]
                        conn = pool.getconn()
                        cursor = conn.cursor()
                        cursor.execute("SELECT 1")
                        pool.putconn(conn)
                        replica.is_healthy = True
                    except:
                        replica.is_healthy = False
                
                time.sleep(interval_seconds)
        
        thread = threading.Thread(target=monitor, daemon=True)
        thread.start()

# Usage
failover = FailoverManager()
failover.add_master("master1", "master.example.com")
failover.add_replica("replica1", "replica1.example.com")
failover.add_replica("replica2", "replica2.example.com")

# Start automatic health monitoring
failover.start_health_monitoring(interval_seconds=10)

# Write always goes to master
def create_order(user_id, items):
    result = failover.write_to_master(
        """INSERT INTO orders (user_id, items)
           VALUES (%s, %s) RETURNING id""",
        (user_id, str(items))
    )
    return result[0]

# Read can use replicas
def get_orders(user_id):
    results = failover.read_from_replica(
        "SELECT * FROM orders WHERE user_id = %s",
        (user_id,)
    )
    return results

# If master dies:
# 1. Health check detects failure (10 seconds)
# 2. Automatically promotes replica to master
# 3. Writes resume (with new master)
# 4. No manual intervention needed!

# Benefits:
# âœ… Automatic failover (no manual steps)
# âœ… High availability (survives master failure)
# âœ… Read scaling (multiple replicas)
# âœ… Production-ready
```

---

## ğŸ’¡ Mini Project: "Build Failover System"

### Phase 1: Master-Slave Replication â­

**Requirements:**
- Setup master database
- Setup replica database
- Replication configuration
- Monitor replication lag

---

### Phase 2: Automatic Failover â­â­

**Requirements:**
- Health check master
- Detect failure
- Promote replica
- Update routing

---

### Phase 3: Multi-Region Failover â­â­â­

**Requirements:**
- Multiple replicas
- Quorum-based promotion
- DNS failover
- Zero-downtime updates

---

## âš–ï¸ Replication Strategies Comparison

| Strategy | Latency | Data Loss | Complexity | Failover Time |
|----------|---------|-----------|-----------|---------------|
| **Async** | Low | Possible | Low | Fast |
| **Sync** | High | None | Medium | Slow |
| **Semi-Sync** | Medium | Minimal | Medium | Medium |
| **Multi-Master** | Low | None | High | Very Fast |

---

## âŒ Common Mistakes

### Mistake 1: Async Replication Without Monitoring

```python
# âŒ Assume replication is instant
write_to_master(order)
read_from_slave(order_id)  # Might not exist yet!

# âœ… Handle replication lag
write_to_master(order)
if need_immediate_read:
    read_from_master(order_id)  # Guaranteed fresh
else:
    read_from_slave_with_timeout(order_id)
```

### Mistake 2: Slave Promotion Without Checks

```python
# âŒ Promote without checking if caught up
promote_replica_to_master(replica)
# Might have lost writes!

# âœ… Check before promoting
if replica.replication_lag < 1000:  # Less than 1000 bytes behind
    promote_replica_to_master(replica)
else:
    alert("Replica too far behind, manual intervention needed")
```

### Mistake 3: No Automatic Failover

```python
# âŒ Manual failover
# Master dies
# On-call engineer gets paged
# 30 minutes downtime

# âœ… Automatic failover
# Master dies
# Health check detects (10 seconds)
# Automatic promotion
# 10 seconds downtime
```

---

## ğŸ“š Additional Resources

**Replication:**
- [PostgreSQL Replication](https://www.postgresql.org/docs/current/warm-standby.html)
- [MySQL Replication](https://dev.mysql.com/doc/refman/8.0/en/replication.html)

**Failover:**
- [Patroni (PostgreSQL failover)](https://github.com/zalando/patroni)
- [MHA (MySQL failover)](https://code.google.com/archive/p/mysql-master-ha/)


---

## ğŸ¯ Before You Leave

**Can you answer these?**

1. **What's master-slave replication?**
   - Answer: Master handles writes, slave copies data

2. **What's failover?**
   - Answer: Automatically switch to backup when primary fails

3. **Async vs sync replication?**
   - Answer: Async = fast + risk; Sync = slow + safe

4. **When to use multi-master?**
   - Answer: When need write to any node, handle conflicts

5. **How long should failover take?**
   - Answer: < 10 seconds for production systems

**If you got these right, you're ready for the next topic!** âœ…

---

## ğŸ¤£ Closing Thoughts

> **Architect:** "We need replication for safety!"
>
> **After setup:** "Replication is 5 seconds behind"
>
> **Then:** "Replication broke, data diverged"
>
> **Then:** "Which replica do we promote?"
>
> **Engineer:** "Just choose one and hope"
>
> **Everyone:** "This is fine." ğŸ”¥

---

[â† Back to Main](../README.md) | [Previous: Heartbeats & Health Checks](34-heartbeats-health-checks.md) | [Next: Circuit Breakers â†’](36-circuit-breakers.md)

---

**Last Updated:** November 11, 2025  
**Difficulty:** â­â­â­â­ Advanced (distributed systems)  
**Time to Read:** 27 minutes  
**Time to Implement:** 6-10 hours per phase  

---

*Failover & Replication: The art of having Plan B, Plan C, and a prayer that Plan A doesn't go down.* ğŸš€