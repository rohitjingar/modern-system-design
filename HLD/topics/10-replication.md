# 10. Replication

Replication is how you copy your database so that when one catches fire, you have a backup catching fire somewhere else. It's not a solution, it's a delay tactic. ğŸ”¥ğŸ”¥

[â† Back to Main](../README.md) | [Previous: Sharding & Partitioning](09-sharding-partitioning.md) | [Next: CAP Theorem â†’](11-cap-theorem.md)

---

## ğŸ¯ Quick Summary

**Replication** is copying data across multiple servers so if one fails, others still have the data. It trades storage space for reliability. There's Master-Slave (simple), Master-Master (complex), and Multi-region (expensive). Each has different consistency and availability guarantees.

Think of it as: **Replication = Backup That's Alive and Ready**

---

## ğŸŒŸ Beginner Explanation

### The Book Analogy

**NO REPLICATION (High Risk):**

```
Library has 1 copy of "The System Design Bible"

Scenario 1: Fire in library ğŸ”¥
Result: Book destroyed, lost forever âŒ

Scenario 2: Someone steals it ğŸ˜±
Result: Book gone, other users disappointed âŒ

Scenario 3: Librarian gets sick ğŸ¤’
Result: No one can check out books today âŒ
```

**WITH REPLICATION (Safe):**

```
Main Library has 1 copy
+ Branch Library has 1 copy (replica)
+ Downtown Library has 1 copy (replica)

Scenario 1: Fire at Main Library ğŸ”¥
Result: Branch and Downtown still have copies âœ…

Scenario 2: Someone steals from Main
Result: Replicas still available âœ…

Scenario 3: Main librarian sick
Result: Branch can serve customers âœ…

Cost: 3x storage, but way more reliable
```

### Master-Slave Replication

**MASTER-SLAVE SETUP:**

```
MASTER (Primary Database)
â”œâ”€ Accepts reads âœ…
â”œâ”€ Accepts writes âœ…
â””â”€ Source of truth

        â†“ (replicates data)

SLAVE 1 (Read Replica 1)
â”œâ”€ Accepts reads only âœ…
â”œâ”€ Cannot write directly âŒ
â””â”€ Copy of data

SLAVE 2 (Read Replica 2)
â”œâ”€ Accepts reads only âœ…
â”œâ”€ Cannot write directly âŒ
â””â”€ Copy of data

OPERATIONS:

Write: Always goes to Master
Client: "Update Alice's email"
Master: Updates âœ…
Master replicates to Slaves (eventually) ğŸ“¦

Read: Can go to Master or Slaves
Client: "Get Alice's data"
Option 1: Master (fresh, slower) ğŸ¢
Option 2: Slave (may be old, faster) âš¡

BENEFITS:
âœ… Read scalability (multiple slaves)
âœ… Backups (slave is always a backup)
âœ… Analytics (run on slave without hitting master)
âœ… Geographic distribution (slave in another region)

PROBLEMS:
âŒ Replication lag (slave temporarily stale)
âŒ Slave can't write (must write to master)
âŒ Master is single point of failure (writes)
```

### Replication Lag (The Hidden Problem)

```
TIME 1:00 PM
Master: Alice's email = old@example.com
Slave: Alice's email = old@example.com

TIME 1:00:01 PM
Client: Update Alice's email to new@example.com
Master: Receives write, updates to new@example.com
Master: Starts replicating to Slave...

TIME 1:00:02 PM (while replication in progress)
Client: Read Alice's email
Query Slave: Returns old@example.com âŒ (Lag!)
Query Master: Returns new@example.com âœ…

TIME 1:00:05 PM (replication done)
Slave: Alice's email = new@example.com
All consistent again âœ…

THE PROBLEM:
Between write and replication completion:
Stale reads are possible! ğŸ˜±
```

---

## ğŸ”¬ Advanced Explanation

### Replication Strategies

**STRATEGY 1: Binary Log Replication (MySQL)**

```
Master writes data, also writes to binary log:

Binary Log on Master:
â”œâ”€ Operation 1: INSERT INTO users VALUES (1, 'Alice')
â”œâ”€ Operation 2: UPDATE users SET email='alice@example.com' WHERE id=1
â”œâ”€ Operation 3: DELETE FROM users WHERE id=2
â””â”€ ...

Slave reads binary log:
â”œâ”€ Read Operation 1 â†’ Execute on local copy
â”œâ”€ Read Operation 2 â†’ Execute on local copy
â”œâ”€ Read Operation 3 â†’ Execute on local copy
â””â”€ Now matches Master âœ…

Benefit: Works with all data (DDL, triggers, etc.)
Problem: Any non-deterministic function breaks replication
         (RAND(), NOW(), UUID())
```

**STRATEGY 2: Row-Based Replication**

```
Instead of replicating SQL statements,
replicate the actual row changes:

Master: UPDATE users SET age = age + 1 WHERE age > 18
        (affects 500,000 rows)

With Statement Replication:
Slave executes: UPDATE users SET age = age + 1 WHERE age > 18
(Same statement, might have different results!)

With Row-Based Replication:
Slave receives: Row 1: age 25â†’26, Row 2: age 30â†’31, ...
(Exact changes, guaranteed same result)

Benefit: Deterministic, guaranteed consistency
Problem: More network traffic (replicate all changes)
```

**STRATEGY 3: MVCC (Multi-Version Concurrency Control)**

```
Master maintains multiple versions of data:

Version 1 (timestamp 100):
  Alice: email = old@example.com, age = 28

Version 2 (timestamp 105):
  Alice: email = new@example.com, age = 28

Transactions see consistent snapshot:
Read at timestamp 100: Gets old email âœ…
Read at timestamp 105: Gets new email âœ…
Both correct, no inconsistency

Benefit: No replication lag for reads!
Problem: More complex, more storage
```

### Master-Master (Active-Active) Replication

**SETUP:**

```
MASTER 1 (Active)         MASTER 2 (Active)
â”œâ”€ Accepts reads âœ…       â”œâ”€ Accepts reads âœ…
â”œâ”€ Accepts writes âœ…      â”œâ”€ Accepts writes âœ…
â””â”€ Replicates to M2       â””â”€ Replicates to M1

Write on M1: User updates email
â”œâ”€ M1 processes write
â”œâ”€ M1 sends to M2
â”œâ”€ M2 applies write

Write on M2: User updates phone
â”œâ”€ M2 processes write
â”œâ”€ M2 sends to M1
â”œâ”€ M1 applies write

Both consistent âœ…

BENEFITS:
âœ… Both servers accept writes
âœ… No single point of failure
âœ… Geographic distribution (lower latency)
âœ… Active-Active (both handling traffic)

PROBLEMS:
âš ï¸ Write conflicts possible
âš ï¸ Cycle detection needed (prevent infinite loops)
âš ï¸ Harder to debug issues
âš ï¸ Complex topology
```

**CONFLICT RESOLUTION:**

```
Conflict Scenario:

M1: Alice sets age = 30
M2: Alice sets age = 25

Same row, same timestamp, different values!
What do we do? ğŸ¤”

Option 1: Last-Write-Wins (LWW)
â”œâ”€ Whichever write came later wins
â”œâ”€ M1 at 1:00:05 PM, M2 at 1:00:03 PM
â”œâ”€ M1 wins: age = 30
â”œâ”€ Problem: Might lose valid data

Option 2: Version Vectors
â”œâ”€ Track causality (which writes depend on which)
â”œâ”€ Merge strategically
â”œâ”€ Problem: Complicated, slow

Option 3: Operational Transformation
â”œâ”€ Transform conflicting operations
â”œâ”€ Like Google Docs real-time collab
â”œâ”€ Problem: Very complex

Option 4: Application Logic
â”œâ”€ Resolve at application level
â”œâ”€ "If age conflict, keep higher value"
â”œâ”€ Problem: Puts burden on dev
```

### Replication Topologies

**TOPOLOGY 1: Star (Master-Slave)**

```
        Master
        /  |  \
       /   |   \
     S1   S2   S3
     
Pros: Simple, clear
Cons: Master bottleneck
```

**TOPOLOGY 2: Chain**

```
Master â†’ S1 â†’ S2 â†’ S3

Pros: Reduces load on master
Cons: Long replication lag, harder to debug
```

**TOPOLOGY 3: Ring (Master-Master)**

```
M1 â†’ M2
â†‘    â†“
M4 â† M3

Pros: No central point of failure
Cons: Circle detection needed, complex
```

**TOPOLOGY 4: Tree**

```
      Master
      /    \
    M1      M2
    / \     / \
   S1 S2   S3 S4

Pros: Scalable, organized
Cons: Very complex
```

### Replication Problems

**PROBLEM 1: Replication Lag**

```
Master writes data
Slave hasn't replicated yet
Client reads stale data

SOLUTIONS:
1. Read from Master (slower but fresh)
2. Accept stale reads (application handles it)
3. Use read-your-writes consistency
   (if you just wrote, read from master)
4. Wait for replication
   (before returning to user: "Replicating...")
```

**PROBLEM 2: Split Brain**

```
Network partition! ğŸ”Œ

M1                    M2
(isolated)            (isolated)

Client 1 writes to M1: age = 25
Client 2 writes to M2: age = 30

When network heals:
What's the truth? 25 or 30? ğŸ˜±

SOLUTION: Quorum-based
Only 1 master can accept writes if < N/2 servers reachable
Prevents both from thinking they're the master
```

**PROBLEM 3: Data Loss on Failover**

```
Master receives write:
Client: "Update Alice"
Master: "Got it, write complete"

Before replication to slaves:
Master: ğŸ’¥ CRASH!

Slaves don't have the update:
- Update is lost âŒ
- Client thinks it worked ğŸ˜±

SOLUTION: Synchronous Replication
Master waits for at least 1 slave to ACK
Before telling client "write complete"
Slower but safer
```

---

## ğŸ Python Code Example

### âŒ Simple Replication (Problems)

```python
# ===== SIMPLE MASTER-SLAVE (PROBLEMS) =====

class SimpleMaster:
    def __init__(self):
        self.data = {}
        self.slaves = []
        self.transaction_log = []
    
    def write(self, key, value):
        """Write to master"""
        self.data[key] = value
        self.transaction_log.append((key, value))
        
        # Replicate to slaves (asynchronous)
        for slave in self.slaves:
            slave.receive_update(key, value)
        
        return True
    
    def read(self, key):
        """Read from master"""
        return self.data.get(key)
    
    def register_slave(self, slave):
        """Add slave replica"""
        self.slaves.append(slave)

class SimpleSlave:
    def __init__(self):
        self.data = {}
    
    def receive_update(self, key, value):
        """Receive update from master"""
        # Simulate network delay
        import time
        time.sleep(0.1)  # 100ms lag
        self.data[key] = value
    
    def read(self, key):
        """Read from slave (might be stale!)"""
        return self.data.get(key)

# Problems with this approach:
# âŒ Replication lag (stale reads possible)
# âŒ No monitoring (don't know if slave is behind)
# âŒ Data loss risk (async replication)
# âŒ No failover handling
```

### âœ… Production Replication (With Solutions)

```python
import time
from enum import Enum
from dataclasses import dataclass
from typing import Dict, List, Optional
import threading

class ReplicationStrategy(Enum):
    ASYNC = "async"           # Fast, data loss risk
    SEMI_SYNC = "semi_sync"   # Balanced
    SYNC = "sync"             # Slow, safe

@dataclass
class ReplicationEvent:
    """Track a replicated event"""
    timestamp: float
    key: str
    value: str
    event_id: int

class ProductionMaster:
    """Production-grade master with replication"""
    
    def __init__(self, strategy: ReplicationStrategy = ReplicationStrategy.SEMI_SYNC):
        self.data: Dict[str, str] = {}
        self.slaves: List['ProductionSlave'] = []
        self.transaction_log: List[ReplicationEvent] = []
        self.event_id = 0
        self.strategy = strategy
        self.lock = threading.Lock()
        self.slave_acks = {}
    
    def write(self, key: str, value: str) -> bool:
        """Write with replication strategy"""
        with self.lock:
            # Write to master first
            self.data[key] = value
            self.event_id += 1
            
            event = ReplicationEvent(
                timestamp=time.time(),
                key=key,
                value=value,
                event_id=self.event_id
            )
            self.transaction_log.append(event)
            
            # Replicate based on strategy
            if self.strategy == ReplicationStrategy.ASYNC:
                # Fire and forget (fast but risky)
                for slave in self.slaves:
                    threading.Thread(
                        target=slave.apply_event,
                        args=(event,)
                    ).start()
                return True
            
            elif self.strategy == ReplicationStrategy.SEMI_SYNC:
                # Wait for at least 1 slave
                acks = 0
                for slave in self.slaves:
                    if slave.apply_event(event):
                        acks += 1
                
                # If at least 1 slave ACKed, we're good
                return acks >= 1
            
            elif self.strategy == ReplicationStrategy.SYNC:
                # Wait for all slaves
                for slave in self.slaves:
                    if not slave.apply_event(event):
                        return False  # If any slave fails, reject write
                return True
    
    def read(self, key: str) -> Optional[str]:
        """Read from master (always fresh)"""
        with self.lock:
            return self.data.get(key)
    
    def register_slave(self, slave: 'ProductionSlave'):
        """Register a slave replica"""
        self.slaves.append(slave)
        self.slave_acks[slave.id] = 0
    
    def get_replication_lag(self) -> Dict[str, float]:
        """Get lag for each slave"""
        lags = {}
        for slave in self.slaves:
            lag = time.time() - slave.last_update
            lags[slave.id] = lag
        return lags
    
    def get_status(self) -> Dict:
        """Get master status"""
        return {
            "data_size": len(self.data),
            "event_count": len(self.transaction_log),
            "slave_count": len(self.slaves),
            "replication_lags": self.get_replication_lag()
        }

class ProductionSlave:
    """Production-grade slave replica"""
    
    def __init__(self, slave_id: str):
        self.id = slave_id
        self.data: Dict[str, str] = {}
        self.last_event_id = 0
        self.last_update = time.time()
        self.lock = threading.Lock()
    
    def apply_event(self, event: ReplicationEvent) -> bool:
        """Apply replicated event"""
        try:
            with self.lock:
                # Simulate network latency
                time.sleep(0.01)  # 10ms lag
                
                # Apply event
                self.data[event.key] = event.value
                self.last_event_id = event.event_id
                self.last_update = time.time()
            
            return True
        except Exception:
            return False
    
    def read(self, key: str) -> Optional[str]:
        """Read from slave (might be stale)"""
        with self.lock:
            return self.data.get(key)
    
    def get_lag(self) -> float:
        """How far behind master am I?"""
        return time.time() - self.last_update

# Usage
print("=== PRODUCTION REPLICATION ===\n")

# Create master and slaves
master = ProductionMaster(strategy=ReplicationStrategy.SEMI_SYNC)
slave1 = ProductionSlave("slave-1")
slave2 = ProductionSlave("slave-2")

master.register_slave(slave1)
master.register_slave(slave2)

# Write data
print("Writing: Alice = alice@example.com")
master.write("alice", "alice@example.com")

# Read from master (always fresh)
print(f"Master read: {master.read('alice')}")

# Read from slave (might be stale)
print(f"Slave 1 read: {slave1.read('alice')}")

# Check replication status
print(f"\nReplication Status:")
status = master.get_status()
for key, value in status.items():
    print(f"  {key}: {value}")

print(f"\nSlave lags:")
for slave in [slave1, slave2]:
    print(f"  {slave.id}: {slave.get_lag():.3f}s behind")
```

### âœ… Failover (Active-Active)

```python
class FailoverManager:
    """Handles master failure and promotion"""
    
    def __init__(self, master: ProductionMaster, slaves: List[ProductionSlave]):
        self.master = master
        self.slaves = slaves
        self.is_healthy = True
    
    def check_master_health(self) -> bool:
        """Check if master is alive"""
        try:
            # Ping master (simplified)
            self.master.read("__health__")
            return True
        except:
            return False
    
    def promote_slave_to_master(self, slave: ProductionSlave) -> ProductionMaster:
        """Promote slave to master"""
        print(f"Promoting {slave.id} to master...")
        
        # Stop replication to this slave
        # Transfer all data to new master
        new_master = ProductionMaster()
        new_master.data = slave.data.copy()
        
        print(f"âœ“ {slave.id} is now master")
        return new_master
    
    def monitor(self):
        """Monitor master health"""
        while True:
            if not self.check_master_health():
                print("âŒ Master failed!")
                # Find healthiest slave
                healthiest = max(
                    self.slaves,
                    key=lambda s: s.last_event_id
                )
                self.promote_slave_to_master(healthiest)
                break
            
            time.sleep(1)  # Check every 1 second

# Usage
# failover = FailoverManager(master, [slave1, slave2])
# failover.monitor()  # Runs in background, detects failures
```

---

## ğŸ’¡ Mini Project: "Build a Replication System"

### Phase 1: Simple Master-Slave â­

**Requirements:**
- Master accepts reads/writes
- Slave accepts reads only
- Async replication
- Basic monitoring

**Code:**
```python
class SimpleReplicationSystem:
    def __init__(self):
        self.master = SimpleMaster()
        self.slaves = []
    
    def add_slave(self):
        slave = SimpleSlave()
        self.master.register_slave(slave)
        self.slaves.append(slave)
    
    def write(self, key, value):
        return self.master.write(key, value)
    
    def read_from_master(self, key):
        return self.master.read(key)
    
    def read_from_slave(self, key):
        # Round-robin to slaves
        for slave in self.slaves:
            return slave.read(key)
```

---

### Phase 2: Advanced (Failover) â­â­

**Requirements:**
- Detect master failure
- Promote slave to master
- Data consistency
- Monitoring dashboard

---

### Phase 3: Enterprise (Multi-Master) â­â­â­

**Requirements:**
- Multiple masters
- Conflict resolution
- Automatic failover
- Health monitoring
- Rebalancing

---

## âš–ï¸ Replication Trade-offs

| Type | Sync | Async | Semi-Sync |
|------|------|-------|-----------|
| **Speed** | Slow âš ï¸ | Fast âœ… | Medium ğŸŸ¡ |
| **Consistency** | Strong âœ… | Weak âŒ | Good âœ… |
| **Data Loss Risk** | None | High | Low |
| **Complexity** | Low | Low | Medium |
| **Latency** | High | Low | Medium |
| **Use Case** | Banking | Analytics | Balance |

---


## âŒ Common Mistakes

### Mistake 1: Async Replication for Critical Data

```python
# âŒ Bank using async replication
# Transaction: -$100 from Alice
# Confirmed to customer immediately
# Master crashes before replication
# âŒ $100 lost!

# âœ… Use semi-sync or sync for critical data
# Transaction confirmed only after at least 1 slave has it
```

### Mistake 2: Ignoring Replication Lag

```python
# âŒ Bad: Write then immediately read
master.write("alice_age", 30)
time.sleep(0.001)  # Too fast!
slave_value = slave.read("alice_age")  # Gets old value
assert slave_value == 30  # âŒ Fails!

# âœ… Good: Wait for replication
master.write("alice_age", 30)
time.sleep(0.5)  # Let replication complete
slave_value = slave.read("alice_age")  # Gets new value âœ…
```

### Mistake 3: Single Master Without Failover

```python
# âŒ Master dies
# All writes impossible
# No automatic recovery
# âŒ Hours of manual intervention

# âœ… Set up automated failover
# Master dies â†’ Slave promoted automatically
# System recovers in seconds
```

## Q : Synchronous vs Asynchronous Replication .


## ğŸ’¡ First, the Core Idea

Replication = **copying data** from one database (primary/master) to another (replica/slave).
This is done to ensure **high availability, backup, and disaster recovery.**

Now, the main question is â€”
ğŸ‘‰ *When* should the replica be updated relative to the master?

Thatâ€™s where **Sync** and **Async** come in.

---

## âš™ï¸ 1ï¸âƒ£ Synchronous Replication

> The primary **waits** until data is **written to both the primary and the replica** before confirming success to the client.

ğŸ§  **In simple terms:**

* â€œIâ€™ll tell the user the write is successful **only after** my backup has also saved it.â€

âœ… **Pros:**

* **Strong consistency** â€” both primary and replica always have same data.
* No data loss if the primary crashes immediately after write.

âŒ **Cons:**

* **Slower writes** â€” because you wait for both to finish.
* If replica is slow or down â†’ it can block writes.

ğŸ’¬ **Use When:**

* You care more about **data accuracy** than speed.
* Example: **Banking, finance, or transaction systems.**

---

## âš™ï¸ 2ï¸âƒ£ Asynchronous Replication

> The primary **does not wait** for the replica to confirm the write.
> It immediately acknowledges success and **replicates later in background**.

ğŸ§  **In simple terms:**

* â€œIâ€™ll save it first, and my replica will catch up soon.â€

âœ… **Pros:**

* **Faster writes** â€” because no waiting for replicas.
* **More scalable** â€” replicas can lag slightly and still handle reads.

âŒ **Cons:**

* **Eventual consistency** â€” replicas may be slightly behind.
* If the primary crashes before replication, **some data can be lost.**

ğŸ’¬ **Use When:**

* You care more about **performance and uptime** than immediate accuracy.
* Example: **Social media posts, analytics, caching layers.**

---

## ğŸ§  Interview Summary Table

| Feature              | **Synchronous Replication**               | **Asynchronous Replication**              |
| -------------------- | ----------------------------------------- | ----------------------------------------- |
| Write acknowledgment | After replica confirms                    | Immediately after master write            |
| Consistency          | Strong (always up-to-date)                | Eventual (replica may lag)                |
| Latency              | High                                      | Low                                       |
| Data loss on crash   | None                                      | Possible                                  |
| Use case             | Banking, Orders, Payments                 | Feeds, Logs, Analytics                    |
| Example systems      | PostgreSQL sync replicas, MySQL semi-sync | MySQL async replicas, MongoDB secondaries |

---

## ğŸ¯ 20-Second Interview Answer (Short & Sharp)

> â€œIn synchronous replication, the primary waits for the replica to confirm the write â€” giving **strong consistency** but **higher latency**.
> In asynchronous replication, the primary doesnâ€™t wait â€” itâ€™s **faster** but may cause **replica lag** or **data loss** if the master crashes.
> So, we choose sync for **critical data**, and async for **scalable or non-critical workloads**.â€

---

## ğŸ§© Bonus Tip (for advanced interviews)

> â€œSome systems use **semi-synchronous replication**, where at least one replica must confirm the write before acknowledging success â€” giving a balance between speed and safety.â€

---


---

## ğŸ“š Additional Resources

**Replication Systems:**
- [MySQL Replication](https://dev.mysql.com/doc/refman/8.0/en/replication.html)
- [PostgreSQL Streaming Replication](https://www.postgresql.org/docs/current/warm-standby.html)
- [MongoDB Replica Sets](https://docs.mongodb.com/manual/replication/)

**Reading:**
- DDIA Chapter 5 - Replication
- "Replication" - Martin Kleppmann
- "Consistency Models in NoSQL"

**Tools:**
- [MySQL Group Replication](https://dev.mysql.com/doc/refman/8.0/en/group-replication.html)
- [etcd](https://etcd.io/) - Distributed coordination
- [Consul](https://www.consul.io/) - Service mesh with replication

---

## ğŸ¯ Before You Leave

**Can you answer these?**

1. **What's the main goal of replication?**
   - Answer: Keep data safe (backup + reliability)

2. **What's replication lag and why does it matter?**
   - Answer: Delay between write and replication; causes stale reads

3. **What's the difference between async and sync replication?**
   - Answer: Async fast/unsafe; sync slow/safe

4. **What's a split brain and how do you prevent it?**
   - Answer: Both masters think they're primary; use quorum voting

5. **How do you promote a slave to master?**
   - Answer: Copy data, stop replication, start accepting writes

**If you got these right, you're ready for the next topic!** âœ…

---

## ğŸ¤£ Closing Thoughts

> **DBA 1:** "I set up replication. System is now safe!"
>
> **DBA 2:** "What replication strategy did you use?"
>
> **DBA 1:** "Async. Data replicates when it feels like it."
>
> **DBA 2:** "...And when the master crashes?"
>
> **DBA 1:** "I lose all pending writes."
>
> **DBA 2:** "That's not safe, that's a time bomb." ğŸ’£

---

[â† Back to Main](../README.md) | [Previous: Sharding & Partitioning](09-sharding-partitioning.md) | [Next: CAP Theorem â†’](11-cap-theorem.md)

---

**Last Updated:** November 10, 2025  
**Difficulty:** â­â­â­ Intermediate-Advanced (distributed systems)  
**Time to Read:** 24 minutes  
**Time to Build System:** 4-6 hours per phase  

---

*Replication: Your insurance policy against that one server that's definitely going to fail at 3 AM.* ğŸš€